services:
  app:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "5000:5000"
    depends_on:
      - ollama  # Asegura que Ollama esté iniciado antes que la app
    volumes:
      - ./src:/app/src
      - C:/Users/jgarcia/OneDrive - ARTICA INGENIERÍA E INNOVACIÓN/Documentos/4. Generacion memorias/config:/app/config
      - C:/Users/jgarcia/OneDrive - ARTICA INGENIERÍA E INNOVACIÓN/Documentos/4. Generacion memorias/data:/app/data
      - C:/Users/jgarcia/OneDrive - ARTICA INGENIERÍA E INNOVACIÓN/Documentos/4. Generacion memorias/logs:/app/logs
  ollama:
    image: ollama/ollama:latest  # Usa la imagen de Ollama que ya tienes
    deploy:
      resources:
        reservations:
          devices:
          - driver: nvidia
            capabilities: ["gpu"]
            count: all  # Adjust count for the number of GPUs you want to use
    volumes:
      - ollama:/root/.ollama
    restart: always
    ports:
      - "11434:11434"
    networks:
      - app-network

networks:
  app-network:
    driver: bridge

volumes:
  ollama: